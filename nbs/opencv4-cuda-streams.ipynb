{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Aug 2018 the OpenCV CUDA api has been exposed to python (for details of the api call's see [test_cuda.py](https://github.com/opencv/opencv/blob/master/modules/python/test/test_cuda.py)).  To get the most from this new functionality you need to have a basic understanding of CUDA (most importantly that it is [data](https://en.wikipedia.org/wiki/Data_parallelism) not [task](https://en.wikipedia.org/wiki/Task_parallelism) parallel) and its interaction with OpenCV.  Below I have tried to introduce these topics with an example of how you could optimize a toy video processing pipeline.  The actual functions called in the pipeline are not important, they are simply there to simulate a common processing pipeline consisting of work performed on both the host (CPU) and device (GPU).\n",
    "\n",
    "This guide is taken from a [Jupyter Notebook](https://jupyter.org/) which can be cloned from here.  The procedure is as follows, following some quick initialization, we start with a [naiive](#naiive) implementation on both the [CPU](#cpu_naiive) and [GPU(#gpu_naiive) to get a baseline result.  We then proceed to incrementaly improve the implementation by using the information provided by the [Nvidia Visual Profiler](https://developer.nvidia.com/nvidia-visual-profiler).\n",
    "\n",
    "On a laptop GTX2080 paired with an i7-8700 the final CUDA incarnation resulted in a speed up of ~29x and ~9x over the naiive CPU and GPU implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents:\n",
    "1. [Naive implementations](#naive)\n",
    "    - [CPU](#cpu_naive)\n",
    "    - [GPU](#gpu_naive)\n",
    "        - [Analysis](#analysis_0)\n",
    "2. [Pre-allocation of return arrays](#pre_allocation)\n",
    "    - [CPU](#cpu_1)\n",
    "    - [GPU](#gpu_1)\n",
    "        - [Analysis](#analysis_1)\n",
    "3. [CUDA Streams](#streams)\n",
    "    - [Replacing the default stream](#gpu_2)\n",
    "        - [Analysis](#analysis_2)\n",
    "    - [Overlap host and device computation - attempt 1](#gpu_3)\n",
    "        - [Analysis](#analysis_3)\n",
    "    - [Overlap host and device computation - attempt 2](#gpu_4)\n",
    "        - [Analysis](#analysis_4)\n",
    "    - [Overlap host and device computation - attempt 3](#gpu_5)\n",
    "        - [Analysis](#analysis_5)\n",
    "    - [Overlap host and device computation - multiple streams](#gpu_6)\n",
    "        - [Analysis](#analysis_6)\n",
    "4. [Analysis without the profiler](#without_profiler)\n",
    "5. [Summary](#summary)\n",
    "6. [Run outside the notebook](#export)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckFg(fg_gs,fg):\n",
    "    if (len(fg_gs) != len(fg)):\n",
    "        return False\n",
    "    for i in range(0,len(fg)):\n",
    "        if(np.sum(fg_gs[i]!=fg[i]) != 0):\n",
    "            return i\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# globals\n",
    "vidPath = os.environ['OPENCV_TEST_DATA_PATH'] + '/cv/video/768x576.avi'\n",
    "lr = 0.05\n",
    "rows_big = 1440\n",
    "cols_big = 2560\n",
    "check_res = False\n",
    "frame_device = cv.cuda_GpuMat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"naive\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ProcVid0(proc_frame_func,lr):\n",
    "    cap = cv.VideoCapture(vidPath)\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "        return\n",
    "    n_frames = 0\n",
    "    start = time.time()\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            n_frames += 1 \n",
    "            proc_frame_func(frame,lr)\n",
    "        else:\n",
    "            break\n",
    "    end = time.time()\n",
    "    cap.release()\n",
    "    return (end - start)*1000/n_frames, n_frames;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cpu_naive\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bgmog2 = cv.createBackgroundSubtractorMOG2()\n",
    "def ProcFrameCPU0(frame,lr,store_res=False):\n",
    "    frame_big = cv.resize(frame,(cols_big,rows_big))\n",
    "    fg_big = bgmog2.apply(frame_big,learningRate = lr)\n",
    "    fg_small = cv.resize(fg_big,(frame.shape[1],frame.shape[0]))\n",
    "    if(store_res):\n",
    "        cpu_res.append(np.copy(fg_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 0 (naive): 100 frames, 30.41 ms/frame\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "cpu_res = []\n",
    "cpu_time_0, n_frames = ProcVid0(partial(ProcFrameCPU0,store_res=check_res),lr)\n",
    "print(f'CPU 0 (naive): {n_frames} frames, {cpu_time_0:.2f} ms/frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gpu_naive\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bgmog2_device = cv.cuda.createBackgroundSubtractorMOG2()\n",
    "def ProcFrameCuda0(frame,lr,store_res=False):\n",
    "    frame_device.upload(frame)\n",
    "    frame_device_big = cv.cuda.resize(frame_device,(cols_big,rows_big))\n",
    "    fg_device_big = bgmog2_device.apply(frame_device_big,lr,cv.cuda.Stream_Null())\n",
    "    fg_device = cv.cuda.resize(fg_device_big,frame_device.size())\n",
    "    fg_host = fg_device.download()\n",
    "    if(store_res):\n",
    "        gpu_res.append(np.copy(fg_host))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 (naive): 100 frames, 3.75 ms/frame\n",
      "Speedup over CPU: 8.11\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "gpu_res = []\n",
    "gpu_time_0, n_frames = ProcVid0(partial(ProcFrameCuda0,store_res=check_res),lr)\n",
    "print(f'GPU 0 (naive): {n_frames} frames, {gpu_time_0:.2f} ms/frame')\n",
    "print(f'Speedup over CPU: {cpu_time_0/gpu_time_0:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gpu_naive](imgs/nvprof_1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__:\n",
    "The image above shows the Nvidia Visual Profiler output from processing 3 of the 100 frames. Important things to be aware of here are:\n",
    "\n",
    "1. The runtime API calls in brown which in this example represent the time the host (CPU) spends waiting for the device (GPU) calls to return.\n",
    "2. The remaining blocks which show the time spent on the device.  This is split according to the operation (kernel, memset, MemCpy(HtoD), MemCpy(DtoH)) aswell as by the CUDA stream which the operations are issued to.  In this case everything is issued to the Default stream. \n",
    "3. In this naiive implementation all device calls from the host are synchronous and as a result the difference between (1) and (2) can be interpreted as periods where no useful work is being performed on either the host or the device. The host is blocking waiting for the device to return and the device is also idle, alocating or freeing memory.\n",
    "4. The gap in between the blocks of runtime API calls representing the time spent executing code on the host, here that is the time taken for OpenCV to read and decode each video frame, `frame = cap.read()`.\n",
    "\n",
    "Taking (1) and (4) into account from left to right the output from the profiler can be mapped to the python calls as:\n",
    "\n",
    "- (1166ms-1168.5ms) `proc_frame_func(frame,lr)`: calls to the device to process the first frame\n",
    "- (1168.5ms-1169.5ms) `frame = cap.read()`: read and decode the second video frame on the host\n",
    "- (1169.5ms) `proc_frame_func(frame,lt)`: calls to the device to process the second frame\n",
    "    \n",
    "Clearly from (3) a lot of time is wasted waiting for the device calls to return, and from (4) there is room for improvement if we are able to overlap host and device computation.\n",
    "\n",
    "__Hypothesis__:\n",
    "The causes of (3) are the blocking calls to both\n",
    "- `cudaMallocPitch()` - OpenCV in python automatically allocates any arrays (numpy or `GpuMat`) which are returned from a function call.  That is on every iteration\n",
    "> `ret, frame = cap.read()`causes memory for the numpy array `frame` to be allocated and destroyed on the host<br>\n",
    "and<br>\n",
    "> `frame_device_big = cv.cuda.resize(frame_device,(cols_big,rows_big))`<br>\n",
    "   `fg_device_big = bgmog2_device.apply(frame_device_big,lr,cv.cuda.Stream_Null())`<br>\n",
    "   `fg_device = cv.cuda.resize(fg_device_big,frame_device.size())` <br>\n",
    "causes memory for `frame_device_big`, `fg_device_big` and `fg_device` to be allocated and destroyed on the device.\n",
    "\n",
    "- `cudaDeviceSynchronise()` - if you don't explicitly pass in a CUDA stream to an OpenCv CUDA function, the default stream will be used and `cudaDeviceSynchronize()` called before the function exits. \n",
    "\n",
    "__Action__:\n",
    "First address the uneccessay calls to `cudaMallocPitch()`, by pre-allocating any output arrays and passing them as input arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pre_allocation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-allocation of return arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ProcVid1(proc_frame,lr):\n",
    "    cap = cv.VideoCapture(vidPath)\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "        return\n",
    "    n_frames = 0\n",
    "    start = time.time()\n",
    "    while(cap.isOpened()):\n",
    "        ret,_ = cap.read(proc_frame.Frame())\n",
    "        if ret == True:\n",
    "            n_frames += 1 \n",
    "            proc_frame.ProcessFrame(lr)\n",
    "        else:\n",
    "            break\n",
    "    end = time.time()\n",
    "    cap.release()\n",
    "    return (end - start)*1000/n_frames, n_frames;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cpu_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProcFrameCpu1:\n",
    "    def __init__(self,rows_small,cols_small,rows_big,cols_big,store_res=False):\n",
    "        self.rows_small, self.cols_small, self.rows_big, self.cols_big = rows_small,cols_small,rows_big,cols_big\n",
    "        self.store_res = store_res\n",
    "        self.res = []\n",
    "        self.bgmog2 = cv.createBackgroundSubtractorMOG2()\n",
    "        self.frame = np.empty((rows_small,cols_small,3),np.uint8)\n",
    "        self.frame_big = np.empty((rows_big,cols_big,3),np.uint8)\n",
    "        self.fg_big = np.empty((rows_big,cols_big),np.uint8)\n",
    "        self.fg_small = np.empty((rows_small,cols_small),np.uint8)\n",
    "        \n",
    "    def ProcessFrame(self,lr):\n",
    "        cv.resize(self.frame,(self.cols_big,self.rows_big),self.frame_big)\n",
    "        self.bgmog2.apply(self.frame_big,self.fg_big,learningRate = lr)\n",
    "        cv.resize(self.fg_big,(self.cols_small,self.rows_small),self.fg_small)\n",
    "        if(self.store_res):\n",
    "            self.res.append(np.copy(self.fg_small))\n",
    "        \n",
    "    def Frame(self):\n",
    "        return self.frame\n",
    "    \n",
    "cap = cv.VideoCapture(vidPath)\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "rows_small,cols_small = frame.shape[:2]\n",
    "proc_frame_cpu1 = ProcFrameCpu1(rows_small,cols_small,rows_big,cols_big,check_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 1 (pre-allocation): 100 frames, 27.81 ms/frame\n",
      "Speedup over CPU baseline: 1.09\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "cpu_time_1, n_frames = ProcVid1(proc_frame_cpu1,lr)\n",
    "print(f'CPU 1 (pre-allocation): {n_frames} frames, {cpu_time_1:.2f} ms/frame')\n",
    "print(f'Speedup over CPU baseline: {cpu_time_0/cpu_time_1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_res: CheckFg(cpu_res,proc_frame_cpu1.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gpu_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProcFrameCuda1:\n",
    "    def __init__(self,rows_small,cols_small,rows_big,cols_big,store_res=False):\n",
    "        self.rows_small, self.cols_small, self.rows_big, self.cols_big = rows_small,cols_small,rows_big,cols_big\n",
    "        self.store_res = store_res\n",
    "        self.res = []\n",
    "        self.bgmog2 = cv.cuda.createBackgroundSubtractorMOG2()\n",
    "        self.frame = np.empty((rows_small,cols_small,3),np.uint8)\n",
    "        self.frame_device = cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)\n",
    "        self.frame_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)        \n",
    "        self.fg_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)\n",
    "        self.fg_device_big.setTo(0)\n",
    "        self.fg_device = cv.cuda_GpuMat(np.shape(frame)[0],np.shape(frame)[1],cv.CV_8UC1)\n",
    "        self.fg_host = np.empty((rows_small,cols_small),np.uint8)\n",
    "        \n",
    "    def ProcessFrame(self,lr):\n",
    "        self.frame_device.upload(self.frame)\n",
    "        cv.cuda.resize(self.frame_device,(cols_big,rows_big),self.frame_device_big)\n",
    "        self.bgmog2.apply(self.frame_device_big,lr,cv.cuda.Stream_Null(),self.fg_device_big)\n",
    "        cv.cuda.resize(self.fg_device_big,self.fg_device.size(),self.fg_device)\n",
    "        self.fg_device.download(self.fg_host)\n",
    "        if(self.store_res):\n",
    "            self.res.append(np.copy(self.fg_host))\n",
    "        \n",
    "    def Frame(self):\n",
    "        return self.frame\n",
    "    \n",
    "proc_frame_cuda1 = ProcFrameCuda1(rows_small,cols_small,rows_big,cols_big,check_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 1 (pre-allocation): 100 frames, 2.03 ms/frame\n",
      "Incremental speedup: 1.85\n",
      "Speedup over CPU: 13.69\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "gpu_time_1, n_frames = ProcVid1(proc_frame_cuda1,lr)\n",
    "print(f'GPU 1 (pre-allocation): {n_frames} frames, {gpu_time_1:.2f} ms/frame')\n",
    "print(f'Incremental speedup: {gpu_time_0/gpu_time_1:.2f}')\n",
    "print(f'Speedup over CPU: {cpu_time_1/gpu_time_1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_res: CheckFg(gpu_res,proc_frame_cuda1.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/nvprof_2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__: Pre-allocating the arrays has successfully removed the calls to `cudaMallocPitch()` and significantly (3 frames are now processed instead of 1.5) reduced (3), the time the host spends waiting for the CUDA runtime to return control to it.\n",
    "\n",
    "__Hypothesis__: As mentioned above by not specifying a stream all calls are placed in the [\"Default\"](https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html) stream which can be seen at the bottom of the figure.  This means that following each asynchronous kernel launch there will be a synchronizing call to `cudaDeviceSynchronize()` shown below:\n",
    "\n",
    "> `cv.cuda.resize(frame_device,(cols_big,rows_big),frame_device_big)` async kernel 1, <br>`cudaDeviceSynchronize()`<br>\n",
    " `bgmog2_device.apply(frame_device_big,lr,cv.cuda.Stream_Null(),fg_device_big)` async kernel 2, <br>`cudaDeviceSynchronize()`<br>\n",
    " `cv.cuda.resize(fg_device_big,fg_device.size(),fg_device)` async kernel 3, \n",
    " <br>`cudaDeviceSynchronize()`<br>\n",
    " `fg_device.download(fg_host)` synchronous copy from device to host\n",
    "\n",
    "__Action__: Pass a non default CUDA stream to each OpenCV CUDA function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"streams\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gpu_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the default stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProcFrameCuda2:\n",
    "    def __init__(self,rows_small,cols_small,rows_big,cols_big,store_res=False):\n",
    "        self.rows_small, self.cols_small, self.rows_big, self.cols_big = rows_small,cols_small,rows_big,cols_big\n",
    "        self.store_res = store_res\n",
    "        self.res = []\n",
    "        self.bgmog2 = cv.cuda.createBackgroundSubtractorMOG2()\n",
    "        self.stream = cv.cuda_Stream()\n",
    "        self.frame = np.empty((rows_small,cols_small,3),np.uint8)\n",
    "        self.frame_device = cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)\n",
    "        self.frame_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)\n",
    "        self.fg_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)\n",
    "        self.fg_device = cv.cuda_GpuMat(np.shape(frame)[0],np.shape(frame)[1],cv.CV_8UC1)\n",
    "        self.fg_host = np.empty((rows_small,cols_small),np.uint8)\n",
    "        \n",
    "    def ProcessFrame(self,lr):\n",
    "        self.frame_device.upload(self.frame,self.stream)\n",
    "        cv.cuda.resize(self.frame_device,(cols_big,rows_big),self.frame_device_big,stream=self.stream)\n",
    "        self.bgmog2.apply(self.frame_device_big,lr,self.stream,self.fg_device_big)\n",
    "        cv.cuda.resize(self.fg_device_big,self.fg_device.size(),self.fg_device,stream=self.stream)\n",
    "        self.fg_device.download(self.stream,self.fg_host)\n",
    "        self.stream.waitForCompletion()  # imidiate wait\n",
    "        if(self.store_res):\n",
    "            self.res.append(np.copy(self.fg_host))\n",
    "        \n",
    "    def Frame(self):\n",
    "        return self.frame\n",
    "    \n",
    "proc_frame_cuda2 = ProcFrameCuda2(rows_small,cols_small,rows_big,cols_big,check_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 2 (replacing the default stream): 100 frames, 2.19 ms/frame\n",
      "Incremental speedup: 0.93\n",
      "Speedup over GPU baseline: 1.71\n",
      "Speedup over CPU: 12.71\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "gpu_time_2, n_frames = ProcVid1(proc_frame_cuda2,lr)\n",
    "print(f'GPU 2 (replacing the default stream): {n_frames} frames, {gpu_time_2:.2f} ms/frame')\n",
    "print(f'Incremental speedup: {gpu_time_1/gpu_time_2:.2f}')\n",
    "print(f'Speedup over GPU baseline: {gpu_time_0/gpu_time_2:.2f}')\n",
    "print(f'Speedup over CPU: {cpu_time_1/gpu_time_2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_res: CheckFg(gpu_res,proc_frame_cuda2.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/nvprof_3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__: The calls to `cudaDeviceSyncronize()` have now been removed and the gaps between the device calls removed, however it looks like the calls to `cudaDeviceSyncronize()` have just been replaced by calls to `cudaMemcpy2DAsync()`.  \n",
    "\n",
    "__Hypothesis__: What has actually happened is we have tried to use asynchronous copies to and from the device without first [pinning the host memory](https://docs.nvidia.com/cuda/cuda-runtime-api/api-sync-behavior.html#api-sync-behavior__memcpy-async).  Therefore what is shown are three asynchronous kernel launches and a synchronous copy from the device to the host, which blocks the host thread until all the previous work on the device is complete:<br>\n",
    "> `cv.cuda.resize(frame_device,(cols_big,rows_big),frame_device_big,stream=stream)` async kernel 1<br>\n",
    " `bgmog2.apply(frame_device_big,lr,stream,fg_device_big)` acync kernel 2<br>\n",
    " `cv.cuda.resize(fg_device_big,fg_device.size(),fg_device,stream=stream)` acync kernel 3<br>\n",
    " `fg_device.download(stream,fg_host)` synchronous copy\n",
    "\n",
    "__Action__: Pin the host memory to address this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gpu_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap host and device computation - attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# host mem not implemented, manually pin memory\n",
    "class PinnedMem(object):\n",
    "    def __init__(self, size, dtype=np.uint8):\n",
    "        self.array = np.empty(size,dtype)\n",
    "        cv.cuda.registerPageLocked(self.array)\n",
    "        self.pinned = True\n",
    "    def __del__(self):\n",
    "        cv.cuda.unregisterPageLocked(self.array)\n",
    "        self.pinned = False\n",
    "    def __repr__(self):\n",
    "        return f'pinned = {self.pinned}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProcFrameCuda3:\n",
    "    def __init__(self,rows_small,cols_small,rows_big,cols_big,store_res=False):\n",
    "        self.rows_small, self.cols_small, self.rows_big, self.cols_big = rows_small,cols_small,rows_big,cols_big\n",
    "        self.store_res = store_res\n",
    "        self.res = []\n",
    "        self.bgmog2 = cv.cuda.createBackgroundSubtractorMOG2()\n",
    "        self.stream = cv.cuda_Stream()\n",
    "        self.frame = PinnedMem((rows_small,cols_small,3))\n",
    "        self.frame_device = cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)\n",
    "        self.frame_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)\n",
    "        self.fg_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)\n",
    "        self.fg_device = cv.cuda_GpuMat(np.shape(frame)[0],np.shape(frame)[1],cv.CV_8UC1)\n",
    "        self.fg_host = PinnedMem((rows_small,cols_small))\n",
    "        \n",
    "    def ProcessFrame(self,lr):\n",
    "        self.frame_device.upload(self.frame.array,self.stream)\n",
    "        cv.cuda.resize(self.frame_device,(cols_big,rows_big),self.frame_device_big,stream=self.stream)\n",
    "        self.bgmog2.apply(self.frame_device_big,lr,self.stream,self.fg_device_big)\n",
    "        cv.cuda.resize(self.fg_device_big,self.fg_device.size(),self.fg_device,stream=self.stream)\n",
    "        self.fg_device.download(self.stream,self.fg_host.array)\n",
    "        self.stream.waitForCompletion() # imidiate wait\n",
    "        if(self.store_res):\n",
    "            self.res.append(np.copy(self.fg_host.array))\n",
    "        \n",
    "    def Frame(self):\n",
    "        return self.frame.array\n",
    "    \n",
    "proc_frame_cuda3 = ProcFrameCuda3(rows_small,cols_small,rows_big,cols_big,check_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 3 (overlap host and device - attempt 1): 100 frames, 1.72 ms/frame\n",
      "Incremental speedup: 1.27\n",
      "Speedup over GPU baseline: 2.18\n",
      "Speedup over CPU: 16.18\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "gpu_time_3, n_frames = ProcVid1(proc_frame_cuda3,lr)\n",
    "print(f'GPU 3 (overlap host and device - attempt 1): {n_frames} frames, {gpu_time_3:.2f} ms/frame')\n",
    "print(f'Incremental speedup: {gpu_time_2/gpu_time_3:.2f}')\n",
    "print(f'Speedup over GPU baseline: {gpu_time_0/gpu_time_3:.2f}')\n",
    "print(f'Speedup over CPU: {cpu_time_1/gpu_time_3:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_res: CheckFg(gpu_res,proc_frame_cuda3.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/nvprof_4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__: The output is now more intuative, that said all that we have done is replace the calls to `cudaDeviceSyncronize()` with calls to `cudaStreamSyncronize()`.  \n",
    "\n",
    "__Hypothesis__: We are issuing asynchronous calls to the device and then imidiately waiting on the host for them to complete.  \n",
    "\n",
    "> `cv.cuda.resize(frame_device,(cols_big,rows_big),frame_device_big,stream=stream)` async kernel 1<br>\n",
    " `bgmog2.apply(frame_device_big,lr,stream,fg_device_big)` async kernel 2<br>\n",
    " `cv.cuda.resize(fg_device_big,fg_device.size(),fg_device,stream=stream)` acync kernel 3<br>\n",
    " `fg_device.download(stream,fg_host.array)` async copy<br>\n",
    " `stream.waitForCompletion()` block until kernel 1-3 and copy have finished\n",
    "\n",
    "What we really want to do is overlap host and device computation by issuing asynchronous calls to the device and then performing processing on the host, before waiting for the asynchronous device calls to return.  For two frames this would be:\n",
    "\n",
    "> `frame_device.upload(frame[0].array,stream)` async copy HtoD, frame 0<br>\n",
    " `cv.cuda.resize(frame_device,(n_cols_big,n_rows_big),frame_device_big,stream=stream)` async kernel 1, frame 0 <br>\n",
    " `bgmog2.apply(frame_device_big,lr,stream,fg_device_big)` async kernel 2, frame 0<br>\n",
    " `cv.cuda.resize(fg_device_big,fg_device.size(),fg_device,stream=stream)` acync kernel 3, frame 0<br>\n",
    " `fg_device.download(stream,fg_host.array)` async copy DtoH, frame 0<br>\n",
    " `ret,_ = cap.read(frame[1].array)` host read frame 1 <br>\n",
    " `stream.waitForCompletion()` block until kernel 1-3 and copy have finished for frame 0\n",
    "\n",
    "__Next__: Move the position of the syncronization point to after a new frame has been read as described above. To do this We also need to increase the number of host frame containers to two because moving the sync point means frame 0 may still be in the process of being uploaded when we decode frame 1. That is, when we call\n",
    "\n",
    ">  `ret,_ = cap.read(frame[1].array)` we have not synced, and we have no way to know if the previous call to `frame_device.upload(frame[0].array,stream)` has finished, hence we need to write to `frame[1].array` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gpu_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap host and device computation - attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ProcVid2(proc_frame,lr,simulate=False):\n",
    "    cap = cv.VideoCapture(vidPath)\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "        return\n",
    "    n_frames = 0\n",
    "    start = time.time()    \n",
    "    while(cap.isOpened()):\n",
    "        ret,_ = cap.read(proc_frame.Frame())\n",
    "        if ret == True:\n",
    "            n_frames += 1\n",
    "            if not simulate:\n",
    "                proc_frame.ProcessFrame(lr)\n",
    "        else:\n",
    "            break\n",
    "    proc_frame.Sync()\n",
    "    end = time.time()    \n",
    "    cap.release()\n",
    "    return (end - start)*1000/n_frames, n_frames;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProcFrameCuda4:\n",
    "    def __init__(self,rows_small,cols_small,rows_big,cols_big,store_res=False):\n",
    "        self.rows_small, self.cols_small, self.rows_big, self.cols_big = rows_small,cols_small,rows_big,cols_big\n",
    "        self.store_res = store_res\n",
    "        self.res = []\n",
    "        self.bgmog2 = cv.cuda.createBackgroundSubtractorMOG2()\n",
    "        self.stream = cv.cuda_Stream()\n",
    "        self.frame_num = 0\n",
    "        self.i_writable_mem = 0\n",
    "        self.frames_in = [PinnedMem((rows_small,cols_small,3)),PinnedMem((rows_small,cols_small,3))]\n",
    "        self.frame_device = cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)\n",
    "        self.frame_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)\n",
    "        self.fg_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)\n",
    "        self.fg_device = cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC1)\n",
    "        self.fg_host = PinnedMem((rows_small,cols_small))\n",
    "        \n",
    "    def ProcessFrame(self,lr):\n",
    "        self.frame_num += 1\n",
    "        if(self.frame_num > 1):\n",
    "            self.stream.waitForCompletion() # wait after we have read the next frame\n",
    "            if(self.store_res):\n",
    "                self.res.append(np.copy(self.fg_host.array))\n",
    "        self.frame_device.upload(self.frames_in[self.i_writable_mem].array, self.stream)\n",
    "        cv.cuda.resize(self.frame_device, (cols_big,rows_big), self.frame_device_big, stream=self.stream)\n",
    "        self.bgmog2.apply(self.frame_device_big, lr, self.stream, self.fg_device_big )\n",
    "        cv.cuda.resize(self.fg_device_big, self.fg_device.size(), self.fg_device, stream=self.stream)\n",
    "        self.fg_device.download(self.stream,self.fg_host.array)\n",
    "        \n",
    "    def Frame(self):\n",
    "        self.i_writable_mem = (self.i_writable_mem + 1) % len(self.frames_in)\n",
    "        return self.frames_in[self.i_writable_mem].array\n",
    "    \n",
    "    def Sync(self):\n",
    "        self.stream.waitForCompletion()\n",
    "        if(self.store_res):\n",
    "            self.res.append(np.copy(self.fg_host.array))\n",
    "    \n",
    "proc_frame_cuda4 = ProcFrameCuda4(rows_small,cols_small,rows_big,cols_big,check_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 4 (overlap host and device - attempt 2): 100 frames, 1.72 ms/frame\n",
      "Incremental speedup: 1.00\n",
      "Speedup over GPU baseline: 2.18\n",
      "Speedup over CPU: 16.18\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "gpu_time_4, n_frames = ProcVid2(proc_frame_cuda4,lr)\n",
    "print(f'GPU 4 (overlap host and device - attempt 2): {n_frames} frames, {gpu_time_4:.2f} ms/frame')\n",
    "print(f'Incremental speedup: {gpu_time_3/gpu_time_4:.2f}')\n",
    "print(f'Speedup over GPU baseline: {gpu_time_0/gpu_time_4:.2f}')\n",
    "print(f'Speedup over CPU: {cpu_time_1/gpu_time_4:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_res: CheckFg(gpu_res,proc_frame_cuda4.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/nvprof_5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__: Changing the synchronization point seems to have done just that moved the wait to before the frame is processed instead of after as we had before.  If we examine the profiler output the runtime api calls still line up perfectly with the device calls in Stream 1616, implying that we are not seeing any host/device processing overlap.\n",
    "\n",
    "Interestingly `CudaStreamSynchronize()` (`stream.waitForCompletion()`) appears to happen directly before processing each frame on the device and not sometime after as we would expect from moving it to after host frame has been read on the host, so whats going on?\n",
    "\n",
    "__Hypothesis__: This is most likely to be because we are working on Windows where the GPU is a Windows Display Driver Model device.  See below for more details.\n",
    "\n",
    "> [CUDA driver has a software queue for WDDM devices to reduce the average overhead of submitting command buffers to the WDDM KMD driver](https://devtalk.nvidia.com/default/topic/548639/is-wddm-causing-this-/)\n",
    "\n",
    "This would cause all the device calls from the pervious frame to be qued and then issued when we call `stream.waitForCompletion()` and could explain the profiler output.  \n",
    "\n",
    "__Next__: Test the hypothesis by forcing the CUDA driver to dispatch all qued calls by issueing a call to `stream.queryIfComplete()` as shown below.\n",
    "\n",
    "> `frame_device.upload(frames_in[0].array, stream)` async copy HtoD, frame 0<br>\n",
    " `cv.cuda.resize(frame_device,(n_cols_big,n_rows_big),frame_device_big,stream=stream)` async kernel 1, frame 0 <br>\n",
    " `bgmog2.apply(frame_device_big, lr, stream, fg_device_big )` async kernel 2, frame 0<br>\n",
    " `cv.cuda.resize(fg_device_big,fg_device.size(),fg_device,stream=stream)` acync kernel 3, frame 0<br>\n",
    " `fg_device.download(stream,fg_host.array)` async copy DtoH, frame 0<br>\n",
    " `stream.queryIfComplete()` __force WDDM to dispatch any qued device calls__<br>\n",
    " `ret,_ = cap.read(frame[1].array)` host read frame 1 <br>\n",
    " `stream.waitForCompletion()` block until kernel 1-3 and copy have finished for frame 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gpu_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap host and device computation - attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProcFrameCuda5:\n",
    "    def __init__(self,rows_small,cols_small,rows_big,cols_big,store_res=False):\n",
    "        self.rows_small, self.cols_small, self.rows_big, self.cols_big = rows_small,cols_small,rows_big,cols_big\n",
    "        self.store_res = store_res\n",
    "        self.res = []\n",
    "        self.bgmog2 = cv.cuda.createBackgroundSubtractorMOG2()\n",
    "        self.stream = cv.cuda_Stream()\n",
    "        self.frame_num = 0\n",
    "        self.i_writable_mem = 0\n",
    "        self.frames_in = [PinnedMem((rows_small,cols_small,3)),PinnedMem((rows_small,cols_small,3))]\n",
    "        self.frame_device = cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)\n",
    "        self.frame_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)\n",
    "        self.fg_device_big = cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)\n",
    "        self.fg_device = cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC1)\n",
    "        self.fg_host = PinnedMem((rows_small,cols_small))\n",
    "        \n",
    "    def ProcessFrame(self,lr):\n",
    "        self.frame_num += 1\n",
    "        if(self.frame_num > 1):\n",
    "            self.stream.waitForCompletion() # wait after we have read the next frame\n",
    "            if(self.store_res):\n",
    "                self.res.append(np.copy(self.fg_host.array))\n",
    "        self.frame_device.upload(self.frames_in[self.i_writable_mem].array, self.stream)\n",
    "        cv.cuda.resize(self.frame_device, (cols_big,rows_big), self.frame_device_big, stream=self.stream)\n",
    "        self.bgmog2.apply(self.frame_device_big, lr, self.stream, self.fg_device_big )\n",
    "        cv.cuda.resize(self.fg_device_big, self.fg_device.size(), self.fg_device, stream=self.stream)\n",
    "        self.fg_device.download(self.stream,self.fg_host.array)\n",
    "        self.stream.queryIfComplete() # kick WDDM\n",
    "        \n",
    "    def Frame(self):\n",
    "        self.i_writable_mem = (self.i_writable_mem + 1) % len(self.frames_in)\n",
    "        return self.frames_in[self.i_writable_mem].array\n",
    "    \n",
    "    def Sync(self):\n",
    "        self.stream.waitForCompletion()\n",
    "        if(self.store_res):\n",
    "            self.res.append(np.copy(self.fg_host.array))\n",
    "    \n",
    "proc_frame_cuda5 = ProcFrameCuda5(rows_small,cols_small,rows_big,cols_big,check_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 5 (overlap host and device - attempt 3): 100 frames, 1.25 ms/frame\n",
      "Incremental speedup: 1.37\n",
      "Speedup over GPU baseline: 3.00\n",
      "Speedup over CPU: 22.25\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "gpu_time_5, n_frames = ProcVid2(proc_frame_cuda5,lr)\n",
    "print(f'GPU 5 (overlap host and device - attempt 3): {n_frames} frames, {gpu_time_5:.2f} ms/frame')\n",
    "print(f'Incremental speedup: {gpu_time_4/gpu_time_5:.2f}')\n",
    "print(f'Speedup over GPU baseline: {gpu_time_0/gpu_time_5:.2f}')\n",
    "print(f'Speedup over CPU: {cpu_time_1/gpu_time_5:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_res:  CheckFg(gpu_res,proc_frame_cuda5.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"analysis_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/nvprof_6.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__: It appears as though the WDDM driver was at fault, by including the extra call to `stream.queryIfComplete()` we have finally overlapped host and device processing.  This can be observed in the profiler output where the gap between runtime api calls (host processing described in 4) overlaps work being performed on the device in Stream 2017.  More importantly the device is almost saturated with only a small gap in between the device calls for each frame in Stream 2017. So what is causing this small gap.\n",
    "\n",
    "__Hypothesis__: From the profiler output is appears that we are still waiting on the host for the device processing to finish `stream.waitForCompletion()`.  Therefore we need a way to issue more work to the device before waiting on the host.  This can easily be achieved by using multiple device streams.  As shown below with just two streams we can to issue commands to the device for frame 0 and 1 before synchronizing on frame 0 leaving even more time for the processing on the device to complete.\n",
    "\n",
    "> `frame_device.upload(frame,stream)` async copy HtoD, frame 0<br>\n",
    " `cv.cuda.resize(frame_device,(n_cols_big,n_rows_big),frame_device_big,stream=stream)` async kernel 1, frame 0 <br>\n",
    " `bgmog2_device.apply(frame_device_big,lr,fg_device_big,stream)` async kernel 2, frame 0<br>\n",
    " `cv.cuda.resize(fg_device_big,fg_device.size(),fg_device,stream=stream)` acync kernel 3, frame 0<br>\n",
    " `fg_device.download(fg_small,stream)` async copy DtoH, frame 0<br>\n",
    " `ret,_ = cap.read(frame)` host read frame 1<br>\n",
    " `stream.waitForCompletion()` block until kernel 1-3 and copy have finished for frame 0\n",
    "\n",
    "__Next__: Use multiple streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gpu_6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap host and device computation - multiple streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SyncType():\n",
    "    none = 1\n",
    "    soft = 2\n",
    "    hard = 3\n",
    "    \n",
    "class ProcFrameCuda6:\n",
    "    def __init__(self,rows_small,cols_small,rows_big,cols_big,n_streams,store_res=False,sync=SyncType.soft,device_timer=False):\n",
    "        self.rows_small, self.cols_small, self.rows_big, self.cols_big = rows_small,cols_small,rows_big,cols_big\n",
    "        self.n_streams = n_streams\n",
    "        self.store_res = store_res        \n",
    "        self.sync = sync\n",
    "        self.bgmog2 = cv.cuda.createBackgroundSubtractorMOG2()\n",
    "        self.frames_device = []\n",
    "        self.frames_device_big = []\n",
    "        self.fgs_device_big = []\n",
    "        self.fgs_device = []\n",
    "        self.fgs_small = []   \n",
    "        self.streams = []\n",
    "        self.frames = []\n",
    "        self.InitMem()\n",
    "        self.InitStreams()\n",
    "        self.res = []\n",
    "        self.i_stream = 0        \n",
    "        self.n_frames = 0\n",
    "        self.device_timer = device_timer\n",
    "        if self.device_timer:\n",
    "            self.events_start = []\n",
    "            self.events_stop = []\n",
    "            self.InitEvents()\n",
    "            self.device_time = 0\n",
    "        \n",
    "    def InitMem(self):\n",
    "        for i in range(0,self.n_streams):\n",
    "            self.frames.append(PinnedMem((rows_small,cols_small,3))) \n",
    "            self.frames_device.append(cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3))\n",
    "            self.frames_device_big.append(cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3))\n",
    "            self.fgs_device_big.append(cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1))\n",
    "            self.fgs_device.append(cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC1))\n",
    "            self.fgs_small.append(PinnedMem((rows_small,cols_small)))\n",
    "            \n",
    "    def InitStreams(self):\n",
    "        for i in range(0,self.n_streams): \n",
    "            if self.sync == SyncType.hard:\n",
    "                self.streams.append(cv.cuda.Stream_Null())\n",
    "            elif self.sync == SyncType.soft:\n",
    "                self.streams.append(cv.cuda_Stream())\n",
    "                \n",
    "    def InitEvents(self):\n",
    "        for i in range(0,self.n_streams):\n",
    "            self.events_start.append(cv.cuda_Event())\n",
    "            self.events_stop.append(cv.cuda_Event()) \n",
    "            \n",
    "    def IncStream(self):\n",
    "        self.i_stream = (self.i_stream+1)%self.n_streams\n",
    "        \n",
    "    def ProcessFrame(self,lr):\n",
    "        self.n_frames += 1\n",
    "        i = self.i_stream\n",
    "        self.IncStream()\n",
    "        stream = self.streams[i]\n",
    "        if(self.n_frames > self.n_streams and self.sync != SyncType.none):            \n",
    "            stream.waitForCompletion() # wait once both streams are used               \n",
    "            #self.events_stop[i].waitForCompletion()\n",
    "            if self.device_timer:  self.device_time += cv.cuda_Event.elapsedTime(self.events_start[i],self.events_stop[i])\n",
    "            #print(f'Dev Time: {self.deviceTime}')\n",
    "            if(self.store_res):\n",
    "                self.res.append(np.copy(self.fgs_small[i].array))\n",
    "        if self.device_timer: self.events_start[i].record(stream)\n",
    "        self.frames_device[i].upload(self.frames[i].array,stream)\n",
    "        cv.cuda.resize(self.frames_device[i], (cols_big,rows_big), self.frames_device_big[i], stream=stream)\n",
    "        self.bgmog2.apply(self.frames_device_big[i], lr, stream, self.fgs_device_big[i])\n",
    "        cv.cuda.resize(self.fgs_device_big[i], self.fgs_device[i].size(), self.fgs_device[i], stream=stream)\n",
    "        self.fgs_device[i].download(stream, self.fgs_small[i].array)\n",
    "        if self.device_timer: self.events_stop[i].record(stream)\n",
    "        stream.queryIfComplete() # kick WDDM       \n",
    "        \n",
    "    def Frame(self):\n",
    "        return self.frames[self.i_stream].array\n",
    "    \n",
    "    def Sync(self):\n",
    "        # sync on last frames\n",
    "        if (self.sync == SyncType.none):\n",
    "            return\n",
    "        \n",
    "        for i in range(0,self.n_streams):\n",
    "            if(not self.streams[self.i_stream].queryIfComplete()):\n",
    "                self.streams[self.i_stream].waitForCompletion()\n",
    "            if(self.store_res):\n",
    "                self.res.append(np.copy(self.fgs_small[self.i_stream].array))\n",
    "            self.IncStream()        \n",
    "            \n",
    "    def FrameTimeMs(self):\n",
    "        if self.device_timer:\n",
    "            return self.device_time/self.n_frames\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "proc_frame_cuda6 = ProcFrameCuda6(rows_small,cols_small,rows_big,cols_big,2,check_res,SyncType.soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 6 (multiple streams): 100 frames, 1.25 ms/frame\n",
      "Incremental speedup: 1.00\n",
      "Speedup over GPU baseline: 3.00\n",
      "Speedup over CPU: 22.25\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "gpu_time_6, n_frames = ProcVid2(proc_frame_cuda6,lr)\n",
    "print(f'GPU 6 (multiple streams): {n_frames} frames, {gpu_time_6:.2f} ms/frame')\n",
    "print(f'Incremental speedup: {gpu_time_5/gpu_time_6:.2f}')\n",
    "print(f'Speedup over GPU baseline: {gpu_time_0/gpu_time_6:.2f}')\n",
    "print(f'Speedup over CPU: {cpu_time_1/gpu_time_6:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_res: CheckFg(gpu_res,proc_frame_cuda6.res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imgs/nvprof_7.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__: The device is now completely saturated with memory operations overlaped with kernel executions.  Additionally the video decoding on the host is now run in parallel with the device code.  This is probably the best we can do for this toy execution pipeline.\n",
    "\n",
    "__Hypothesis__: Now that the host/device and kernel/memory operations are overlapped the average time to process each frame should be less than the average time required to process each frame on the device.\n",
    "\n",
    "__Next__:\n",
    "1. Time the execution on the device using device timers to get the average time required to process each frame on the device.  Unfortunately this introduces some overhead so we will have to compare this to the average time required to process each frame calculated without the device timers.  This may mean that we may not see the difference that we expect.\n",
    "2. Calculate the theoretical average time to process each frame on the host and then the device without overlap, to see what we have gained from host/device and kernel/memory overlap.\n",
    "3. Calculate the average wasted time on the host (time where the host could be perfoming useful operations without increasing the average processing time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"without_profiler\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis without the profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean times calculated over 100 frames:\n",
      "Time to process each frame on the device: 0.97 ms/frame\n",
      "Time to process each frame (host/device): 1.25 ms/frame\n",
      "-> Gain from memcpy/kernel overlap if device is saturated: -0.28 ms/frame\n",
      "Time to read and decode each frame on the host: 0.62 ms/frame\n",
      "-> Total processing time host + device: 1.59 ms/frame\n",
      "-> Gain from host/device overlap: 0.34 ms/frame\n",
      "-> Currently waisted time on host: 0.63 ms/frame\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "proc_frame_cuda7 = ProcFrameCuda6(rows_small,cols_small,rows_big,cols_big,2,check_res,SyncType.soft,True)\n",
    "ProcVid2(proc_frame_cuda7,lr)\n",
    "print(f'Mean times calculated over {n_frames} frames:')\n",
    "print(f'Time to process each frame on the device: {proc_frame_cuda7.FrameTimeMs():.2f} ms/frame')\n",
    "print(f'Time to process each frame (host/device): {gpu_time_6:.2f} ms/frame')\n",
    "print(f'-> Gain from memcpy/kernel overlap if device is saturated: {proc_frame_cuda7.FrameTimeMs()-gpu_time_6:.2f} ms/frame')\n",
    "hostTime, n_frames = ProcVid2(proc_frame_cuda6, lr, True)\n",
    "print(f'Time to read and decode each frame on the host: {hostTime:.2f} ms/frame')\n",
    "print(f'-> Total processing time host + device: {proc_frame_cuda7.FrameTimeMs()+hostTime:.2f} ms/frame')\n",
    "print(f'-> Gain from host/device overlap: {proc_frame_cuda7.FrameTimeMs()+hostTime - gpu_time_6:.2f} ms/frame')\n",
    "print(f'-> Currently waisted time on host: {gpu_time_6-hostTime:.2f} ms/frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling OpenCV CUDA functions the most effective optimizations (in order of effectiveness/ease to implement) for this toy problem are given below.  Whilst (1) will always be effective, the other optimizations will heavily depend on the CPU/GPU specifications, data size and the amount of processing which can be perfomed on the device before returing to the host.  Therefore it is always beneficial to use a tool such as the Nvidia visual profiler to analyze your pipeline as you make changes.\n",
    "1. Pre-allocate and pass all GpuMat arrays (making sure they are the correct size) as function arguments to avoid them being allocated each time the function is called.\n",
    "2. Try to design a processing pipeline which allows memory copies to overlap kernel calls and work to be performed on both the host and the device at the same time.\n",
    "3. Use CUDA streams with pinned host memory and if you are working on windows consider calling `stream.queryIfComplete()` to force the WDDM driver to dispatch the CUDA calls.\n",
    "4. Use multiple streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"export\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run outside the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted opencv4-cuda-streams.ipynb to exp\\nb_opencv4-cuda-streams.py\n"
     ]
    }
   ],
   "source": [
    "# taken from https://github.com/fastai/fastai_docs/blob/master/dev_nb/notebook2script.py\n",
    "!python notebook2script.py \"opencv4-cuda-streams.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 0 (naive): 100 frames, 29.84 ms/frame\n",
      "GPU 0 (naive): 100 frames, 8.90 ms/frame\n",
      "Speedup over CPU: 3.35\n",
      "CPU 1 (pre-allocation): 100 frames, 27.49 ms/frame\n",
      "Speedup over CPU baseline: 1.09\n",
      "GPU 1 (pre-allocation): 100 frames, 2.03 ms/frame\n",
      "Incremental speedup: 4.38\n",
      "Speedup over CPU: 13.54\n",
      "GPU 2 (replacing the default stream): 100 frames, 1.87 ms/frame\n",
      "Incremental speedup: 1.08\n",
      "Speedup over GPU baseline: 4.75\n",
      "Speedup over CPU: 14.66\n",
      "GPU 3 (overlap host and device - attempt 1): 100 frames, 1.72 ms/frame\n",
      "Incremental speedup: 1.09\n",
      "Speedup over GPU baseline: 5.18\n",
      "Speedup over CPU: 16.00\n",
      "GPU 4 (overlap host and device - attempt 2): 100 frames, 1.72 ms/frame\n",
      "Incremental speedup: 1.00\n",
      "Speedup over GPU baseline: 5.18\n",
      "Speedup over CPU: 16.00\n",
      "GPU 5 (overlap host and device - attempt 3): 100 frames, 1.09 ms/frame\n",
      "Incremental speedup: 1.57\n",
      "Speedup over GPU baseline: 8.14\n",
      "Speedup over CPU: 25.14\n",
      "GPU 6 (multiple streams): 100 frames, 0.94 ms/frame\n",
      "Incremental speedup: 1.17\n",
      "Speedup over GPU baseline: 9.50\n",
      "Speedup over CPU: 29.33\n",
      "Mean times calculated over 100 frames:\n",
      "Time to process each frame on the device: 0.92 ms/frame\n",
      "Time to process each frame (host/device): 0.94 ms/frame\n",
      "-> Gain from memcpy/kernel overlap if device is saturated: -0.02 ms/frame\n",
      "Time to read and decode each frame on the host: 0.62 ms/frame\n",
      "-> Total processing time host + device: 1.55 ms/frame\n",
      "-> Gain from host/device overlap: 0.61 ms/frame\n",
      "-> Currently waisted time on host: 0.31 ms/frame\n",
      "[ INFO:0] global E:\\Dev\\Repos\\opencv_fork_1\\modules\\videoio\\src\\videoio_registry.cpp (187) cv::`anonymous-namespace'::VideoBackendRegistry::VideoBackendRegistry VIDEOIO: Enabled backends(7, sorted by priority): FFMPEG(1000); GSTREAMER(990); INTEL_MFX(980); MSMF(970); DSHOW(960); CV_IMAGES(950); CV_MJPEG(940)\n"
     ]
    }
   ],
   "source": [
    "! python exp/nb_opencv4-cuda-streams.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
